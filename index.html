<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hung-Ting Su</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: 'Roboto', sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f4f4f4;
            padding: 20px;
            max-width: 900px; /* To narrow the layout */
            margin: 0 auto;
        }
        header {
            text-align: center;
            margin-bottom: 40px;
        }
        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        header p {
            font-size: 1.2em;
            color: #777;
        }
        section {
            margin-bottom: 40px;
        }
        h2 {
            font-size: 2em;
            color: #222;
            margin-bottom: 20px;
        }
        .bio, .news, .publications {
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        .publications ul {
            list-style-type: none;
        }
        .publications li {
            margin-bottom: 15px;
        }
        footer {
            text-align: center;
            padding: 20px;
            margin-top: 40px;
            font-size: 0.9em;
            color: #777;
        }
    </style>
</head>
<body>

    <header style="display: flex; align-items: center;">
        <img src="profile.jpeg" alt="Profile Photo of Hung-Ting Su" style="border-radius: 50%; width: 150px; height: 150px; margin-right: 20px;">
        <div>
            <h1>Hung-Ting Su</h1>
            <p>Postdoctoral Researcher, National Taiwan University</p>
            <p>
                <a href="mailto:hungtingsu.tw@gmail.com">Email</a> | 
                <a href="https://scholar.google.com/citations?user=5oNVau8AAAAJ&hl" target="_blank">Google Scholar</a> | 
                <a href="https://www.linkedin.com/in/hung-ting-su-3a73a8224/" target="_blank">LinkedIn</a>
            </p>
        </div>
    </header>

    <section class="bio">
        <h2>Bio</h2>
        <p>
            Hung-Ting Su is a postdoctoral researcher at the Communications and Multimedia Lab, National Taiwan University, under the supervision of Prof. Winston H. Hsu. He was a visiting scholar at Columbia University, where he worked with Prof. Shih-Fu Chang. He obtained his Ph.D. from National Taiwan University, also under the supervision of Prof. Winston H. Hsu. He collaborates closely with Prof. Min Sun, Prof. Hung-Yi Lee, and Prof. Pu-Jen Cheng. <br>
            <strong>I am actively seeking full-time or internship positions as a research or applied scientist for 2025.</strong>
        </p>
    </section>

    <section class="news">
        <h2>News</h2>
        <div class="news-list">
            <p><strong>Sep 2024:</strong> One first author paper accepted to <strong>EMNLP 2024</strong>.</p>
<p><strong>Sep 2024:</strong> One first author paper accepted to <strong>CoRL 2024</strong>.</p>
<p><strong>Aug 2024:</strong> Honored to receive the <strong>PhD Thesis Award</strong> from the <strong>IEEE Taipei Section</strong>.</p>
<p><strong>May 2024:</strong> One paper accepted to <strong>IJCAI 2024</strong>.</p>
<p><strong>Jan 2024:</strong> One paper accepted to <strong>WWW 2024</strong>.</p>


        </div>
    </section>
    <section class="publications">
    <h2>Publications</h2>
    <ul>
        <li>
            <strong><a href="https://arxiv.org/abs/2409.14324">Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses</a></strong><br>
            <strong><em>Hung-Ting Su</em></strong>, Ya-Ching Hsu, Xudong Lin, Xiang-Qian Shi, Yulei Niu, Han-Yuan Hsu, Hung-yi Lee, Winston H. Hsu.<br>
            Empirical Methods in Natural Language Processing findings (<strong>EMNLP</strong>), 2024.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2409.04837">Context-Aware Replanning with Pre-Explored Semantic Map for Object Navigation</a></strong><br>
            <strong><em>Hung-Ting Su</em></strong>, Ching-Yuan Chen, Po-Chen Ko, Jia-Fong Yeh, Min Sun, Winston H. Hsu.<br>
            Conference on Robot Learning <strong>(CoRL)</strong>, 2024.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2405.17507">Enhancing Sustainable Urban Mobility Prediction with Telecom Data: A Spatio-Temporal Framework Approach</a></strong><br>
            Chung-Yi Lin, Shen-Lung Tung, <strong><em>Hung-Ting Su</em></strong>, and Winston H. Hsu.<br>
            International Joint Conference on Artificial Intelligence <strong>(IJCAI)</strong>, 2024.
        </li>
        <li>
            <strong><a href="https://dl.acm.org/doi/abs/10.1145/3589335.3651442">Tel2Veh: Fusion of Telecom Data and Vehicle Flow to Predict Camera-Free Traffic via a Spatio-Temporal Framework</a></strong><br>
            Chung-Yi Lin, Shen-Lung Tung, <strong><em>Hung-Ting Su</em></strong>, and Winston H. Hsu.<br>
            The Web Conference <strong>(WWW)</strong>, 2024.
        </li>
        <li>
            <strong><a href="https://ojs.aaai.org/index.php/AAAI/article/view/30331">TelTrans: Applying Multi-Type Telecom Data to Transportation Evaluation and Prediction via Multifaceted Graph Modeling</a></strong><br>
            Chung-Yi Lin, Shen-Lung Tung, <strong><em>Hung-Ting Su</em></strong>, and Winston H. Hsu.<br>
            AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong>, 2024.
        </li>
        <li>
            <strong><a href="https://dl.acm.org/doi/abs/10.1145/3583780.3615116">CTCam: Enhancing Transportation Evaluation through Fusion of Cellular Traffic and Camera-Based Vehicle Flows</a></strong><br>
            Chung-Yi Lin, Shen-Lung Tung, <strong><em>Hung-Ting Su</em></strong>, and Winston H. Hsu.<br>
            The Conference on Information and Knowledge Management <strong>(CIKM)</strong>, 2023.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2304.03754">Language Models are Causal Knowledge Extractors for Zero-shot Video Question Answering</a></strong><br>
            <strong><em>Hung-Ting Su</em></strong>, Yulei Niu, Xudong Lin, Winston H. Hsu, and Shih-Fu Chang.<br>
            CVPR Workshop on Learning with Limited Labelled Data for Image and Video Understanding <strong>(CVPRW)</strong>, 2023.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2210.03941">Learning Fine-Grained Visual Understanding for Video Question Answering via Decoupling Spatial-Temporal Modeling</a></strong><br>
            Hsin-Ying Lee, <strong><em>Hung-Ting Su</em></strong>, Bing-Chen Tsai, Tsung-Han Wu, Jia-Fong Yeh, and Winston H. Hsu.<br>
            British Machine Vision Conference <strong>(BMVC)</strong>, 2022.
        </li>

        <li>
            <strong><a href="https://arxiv.org/abs/2203.10981">MonoDTR: Monocular 3D Object Detection with Depth-Aware Transformer</a></strong> <br>
            Kuan-Chih Huang, Tsung-Han Wu, <strong><em>Hung-Ting Su</em></strong>, and Winston H. Hsu.<br>
            Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2022.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2112.02278">Stage Conscious Attention Network (SCAN): A Demonstration-Conditioned Policy for Few-Shot Imitation</a></strong><br>
            Jia-Fong Yeh, Chi-Ming Chung, <strong><em>Hung-Ting Su</em></strong>, Yi-Ting Chen, and Winston H. Hsu.<br>
            AAAI Conference on Artificial Intelligence <strong>(AAAI)</strong>, 2022.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2108.08307">Multivariate and Propagation Graph Attention Network for Spatial-Temporal Prediction with Outdoor Cellular Traffic</a></strong><br>
            Chung-Yi Lin, <strong><em>Hung-Ting Su</em></strong>, Shen-Lung Tung, and Winston H. Hsu.<br>
            ACM International Conference on Information and Knowledge Management <strong>(CIKM)</strong>, 2021.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2108.04542">TrUMAn: Trope Understanding in Movies and Animations</a></strong> <br>
            <strong><em>Hung-Ting Su</em></strong>, Po-Wei Shen, Bing-Chen Tsai, Wen-Feng Cheng, Ke-Jyun Wang, and Winston H. Hsu.<br>
            ACM International Conference on Information and Knowledge Management <strong>(CIKM)</strong>, 2021.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2107.11769">ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation</a></strong> <br>
            Tsung-Han Wu, Yueh-Cheng Liu, Yu-Kai Huang, Hsin-Ying Lee, <strong><em>Hung-Ting Su</em></strong>, Ping-Chia Huang, and Winston H. Hsu.<br>
            International Conference on Computer Vision <strong>(ICCV)</strong>, 2021.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2102.12152">Dual-Awareness Attention for Few-Shot Object Detection</a></strong> <br>
            Tung-I Chen, Yueh-Cheng Liu, <strong><em>Hung-Ting Su</em></strong>, Yu-Cheng Chang, Yu-Hsiang Lin, Jia-Fong Yeh, Wen-Chin Chen, and Winston H. Hsu.<br>
            IEEE Transactions on Multimedia <strong>(TMM)</strong>.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2101.01447">End-to-End Video Question Answer Generation with Generator-Pretester Network</a></strong><br>
            <strong><em>Hung-Ting Su</em></strong>, Chen-Hsi Chang, Po-Wei Shen, Yu-Siang Wang, Ya-Liang Chang, Yu-Cheng Chang, Pu-Jen Cheng, and Winston H. Hsu.<br>
            IEEE Transactions on Circuits and Systems for Video Technology <strong>(TCSVT)</strong>.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2103.07679">OCID-Ref: A 3D Robotic Dataset With Embodied Language for Clutter Scene Grounding</a></strong><br>
            Ke-Jyun Wang, Yun-Hsuan Liu, <strong><em>Hung-Ting Su</em></strong>, Jen-Wei Wang, Yu-Siang Wang, Winston H. Hsu, and Wen-Chin Chen.<br>
            North American Chapter of the Association for Computational Linguistics <strong>(NAACL)</strong>, 2021.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2103.02396">$S^{3}$: Learnable Sparse Signal Superdensity for Guided Depth Estimation</a></strong><br>
            Yu-Kai Huang, Yueh-Cheng Liu, Tsung-Han Wu, <strong><em>Hung-Ting Su</em></strong>, Yu-Cheng Chang, Tsung-Lin Tsou, Yu-An Wang, and Winston H. Hsu.<br>
            Computer Vision and Pattern Recognition <strong>(CVPR)</strong>, 2021.
        </li>
        <li>
            <strong><a href="https://arxiv.org/abs/2101.07632">Situation and Behavior Understanding by Trope Detection on Films</a></strong> <br>
            Chen-Hsi Chang*, <strong><em>Hung-Ting Su*</em></strong>, Jui-Heng Hsu, Yu-Siang Wang, Yu-Cheng Chang, Zhe Yu Liu, Ya-Liang Chang, Wen-Feng Cheng, Ke-Jyun Wang, and Winston H. Hsu.<br>
            (*: Equal Contribution) <br>
            The Web Conference <strong>(WWW)</strong>, 2021.
        </li>

            <li>
                <a href="https://arxiv.org/abs/2010.10695"><strong>Class-agnostic Few-shot Object Counting</strong></a><br>
                Shuo-Diao Yang, <strong><em>Hung-Ting Su</em></strong>, Winston H. Hsu, and Wen-Chin Chen.<br>
                Workshop on Applications of Computer Vision <strong>(WACV)</strong>, 2021.
            </li>
            <li>
                <a href="https://arxiv.org/abs/2010.10695"><strong>A Coarse-To-Fine (C2F) Representation for End-To-End 6-DoF Grasp Detection</strong></a><br>
                Kuang-Yu Jeng, Yueh-Cheng Liu, Zhe-Yu Liu, Jen-Wei Wang, Ya-Liang Chang, <strong><em>Hung-Ting Su</em></strong>, and Winston H. Hsu.<br>
                The Conference on Robot Learning <strong>(CoRL)</strong>, 2020.
            </li>
            <li>
                <a href="https://arxiv.org/abs/1907.03049"><strong>Video Question Generation via Semantic Rich Cross-Modal Self-Attention Networks Learning</strong></a><br>
                Yu-Siang Wang*, <strong><em>Hung-Ting Su*</em></strong>, Chen-Hsi Chang, Zhe-Yu Liu, and Winston H. Hsu.<br>
                (*: Equal Contribution) <br>
                IEEE Conference on Acoustics, Speech, and Signal Processing <strong>(ICASSP)</strong>, 2020.
            </li>
        </ul>
    </section>

    <footer>
        &copy; 2024 Dr. Hung-Ting Su. All Rights Reserved.
    </footer>

</body>
</html>
